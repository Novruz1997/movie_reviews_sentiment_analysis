# -*- coding: utf-8 -*-
"""Sentiment_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FUKVrzOfeazgaHD113t3sdtzhgOIIUpv
"""

import nltk
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from nltk.sentiment import SentimentIntensityAnalyzer
from statistics import mean
from nltk import NaiveBayesClassifier
from random import shuffle
from sklearn.naive_bayes import (
    BernoulliNB,
    MultinomialNB,
)
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
nltk.download([ "names",
              "stopwords",
              "state_union",
              "twitter_samples",
              "movie_reviews",
              "averaged_perceptron_tagger",
              "vader_lexicon",
              "punkt"])

class TextPreprocessor(object):
  '''Preprocessing of raw text data, convert it into suitable format for Text Classifier'''

  stop_words = nltk.corpus.stopwords.words('english')
  stop_words.extend([w.lower() for w in nltk.corpus.names.words()])

  def __init__(self, word_list):
    self.word_list = word_list
    self.positive_word_freq = self._positive_word_freq()
    self.negative_word_freq = self._negative_word_freq()
    self.common_set = self._common_words()
    self.top_100_negative = self._find_top_100_negative()
    self.top_100_positive = self._find_top_100_positive()

  def remove_words(self, word_tuple):
    word, tag = word_tuple
    if not word.isalpha() or word in self.stop_words:
      return False
    if tag.startswith('NN'):
      return False
    return True

  def _find_words(self, category):
    words = [word for word, tag in filter(
                                self.remove_words, 
                                nltk.pos_tag(self.word_list))]
    return words

  def find_positive_words(self):
    '''finding all positive words in txt file'''
    return self._find_words(category = 'pos')
  def find_negative_words(self):
    '''finding all negative words in txt file'''
    return self._find_words(category = 'neg')

  def _positive_word_freq(self):
    positive_fd = nltk.FreqDist(self.find_positive_words())
    return positive_fd

  def _negative_word_freq(self):
    negative_fd = nltk.FreqDist(self.find_negative_words())
    return negative_fd
  
  def _common_words(self):
    common_w = set(self.positive_word_freq).intersection(self.negative_word_freq)
    return common_w

  def _find_top_100_positive(self):
    return {word for word, count in self.positive_word_freq.most_common(100)}

  def _find_top_100_negative(self):
    return {word for word, count in self.negative_word_freq.most_common(100)}

  def extract_features(self, text):
    '''Classification of Sentence with NLTK buildin sentiment analyzer
       VADER (Valence Aware Dictionary and Sentiment Reasoner) '''
    sia = SentimentIntensityAnalyzer()
    features = dict()
    wordcount = 0
    compound_scores = list()
    positive_scores = list()

    for sentence in nltk.sent_tokenize(text):
      for word in nltk.word_tokenize(sentence):
        if word.lower() in self.top_100_positive:
          wordcount += 1
      compound_scores.append(sia.polarity_scores(sentence)['compound'])
      positive_scores.append(sia.polarity_scores(sentence)['pos'])

    features['mean_compound'] = mean(compound_scores) + 1 # 1 added for each compound score, some classifiers words only positive numbers
    features['mean_positive'] = mean(positive_scores)
    features['wordcount'] = wordcount
    return features

  def plot_top_100(self, category):
    '''plotting top 100 words either positive or negative'''
    try:
      if category in ['positive', 'negative']:
        if category == 'positive':
          x = WordCloud().generate(' '.join(list(self.top_100_positive)))
          plt.imshow(x, interpolation='bilinear')
          plt.axis('off')
          plt.show()
        else:
          x = WordCloud().generate(' '.join(list(self.top_100_negative)))
          plt.imshow(x, interpolation='bilinear')
          plt.axis('off')
          plt.show()
    except ValueError:
      print('category mush be either positive of negative')

text_preprocessor = TextPreprocessor(nltk.corpus.movie_reviews.words())
features = [
            (text_preprocessor.extract_features(nltk.corpus.movie_reviews.raw(review)), 'pos') 
            for review in nltk.corpus.movie_reviews.fileids(categories=['pos'])
            ]

features.extend([
                 (text_preprocessor.extract_features(nltk.corpus.movie_reviews.raw(review)), 'neg')
                 for review in nltk.corpus.movie_reviews.fileids(categories=['neg'])
])

class Classification(object):
  def __init__(self, classifier):
    self.classifier = classifier

  def train_test_split(self, data, percent = 0.4):
    shuffle(data)
    train_data = data[:round(len(data)*percent)]
    test_data = data[round(len(data)*percent):] 
    return test_data, train_data

  def train_classifier(self, training_set, method = None):
    if method == 'sklearn':
      self.classifier =  nltk.classify.SklearnClassifier(self.classifier)
      return self.classifier.train(training_set)
    else:
      return self.classifier.train(training_set)

nb_classifier = Classification(NaiveBayesClassifier)
test_data, train_data = nb_classifier.train_test_split(features)
classifer = nb_classifier.train_classifier(train_data)
classifer.show_most_informative_features(10)
# nltk.classify.accuracy(classifer, test_data)

nltk.classify.accuracy(classifer, test_data)

classifiers = {
    "BernoulliNB": BernoulliNB(),
    "MultinomialNB": MultinomialNB(),
    "KNeighborsClassifier": KNeighborsClassifier(),
    "DecisionTreeClassifier": DecisionTreeClassifier(),
    "RandomForestClassifier": RandomForestClassifier(),
}




if __name__ == '__main__':
  for name, classifier in classifiers.items():
    cls = Classification(classifier)
    test_data, train_data = cls.train_test_split(features)
    pred = cls.train_classifier(train_data, method = 'sklearn')
    accuracy = nltk.classify.accuracy(pred, test_data)
    print('Accuracy for {0} classifier is {1}'.format(name, round(accuracy, 2)))

